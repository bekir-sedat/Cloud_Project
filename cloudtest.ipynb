{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "cloudtest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uAajJIECeJ56",
        "colab_type": "code",
        "outputId": "e0332249-0ee5-4a3a-8257-603dcceb0bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import keras, warnings\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import csv\n",
        "from tensorflow.python.client import device_lib\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 11468054659582691581\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 5042321174428224210\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 16302848543798239753\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 15956161332\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 9099756955270269506\n",
            "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52F8rOC2aCIR",
        "colab_type": "code",
        "outputId": "30ed10dd-6496-4248-b416-2dbc881da1fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VjsaEOCKeJ6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in os.listdir(\"/kaggle/input/modelcloud\"):\n",
        "    print(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7PlEdMkJerI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_xtrain_images  = \"/content/gdrive/My Drive/Cloud/train_images\n",
        "dir_test_images  = \"/content/gdrive/My Drive/Cloud/test_images\"\n",
        "dir_y_train_files = \"/content/gdrive/My Drive/Cloud/Final_Segmented_Files\"\n",
        "dir_csv_output_file = \"/content/gdrive/My Drive/Cloud/CSV/mysubmissiohn.csv\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "iJ-nuL6xeJ6L",
        "colab_type": "code",
        "outputId": "d4a9a707-a68b-4eaa-8f83-82f460970b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"/content/gdrive/My Drive/Cloud/Models/model178.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5rGQWhZeeJ6U",
        "colab_type": "code",
        "outputId": "846b6fe6-3c81-4aa8-fc0c-a7059e536e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "x_test_List = []\n",
        "for file in os.listdir(dir_test_images):\n",
        "    #print(file)\n",
        "    x_test_List.append(dir_test_images+'/'+file)\n",
        "    \n",
        "x_test_List.sort()    \n",
        "print('Total training Images: ' + str(len(x_test_List)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training Images: 3698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYua9BAz8yMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetEndodedList(y_predicted,c):\n",
        "    List = []\n",
        "    \n",
        "    numberOfRunningPixel = 0\n",
        "    \n",
        "    addable = False\n",
        "    \n",
        "    for w in range(525):\n",
        "        \n",
        "                for h in range(350):\n",
        "                \n",
        "                    if(int(y_predicted[h,w]) == c and numberOfRunningPixel >0):\n",
        "                        addable =True\n",
        "                        #wasPreviousSame = False\n",
        "                        buf = numberOfRunningPixel\n",
        "                        numberOfRunningPixel +=1\n",
        "                        \n",
        "                        continue\n",
        "                        \n",
        "                        \n",
        "                    elif(int(y_predicted[h,w]) == c and numberOfRunningPixel ==0 ):      \n",
        "                        \n",
        "                        addable =True\n",
        "                        start = (w*350)+(h+1)\n",
        "                        \n",
        "                        numberOfRunningPixel +=1\n",
        "                        \n",
        "                        if(start % 350 == 0):\n",
        "                            start = (w+1)*350\n",
        "                        \n",
        "                        List.append(start)\n",
        "                        \n",
        "                        #take care running here \n",
        "                        \n",
        "                    if( addable and not (y_predicted[h,w] == c)  ):\n",
        "                        \n",
        "                        addable = False\n",
        "                        \n",
        "                        List.append(numberOfRunningPixel)\n",
        "                        \n",
        "                        numberOfRunningPixel = 0\n",
        "                            \n",
        "                             \n",
        "                        \n",
        "                        \n",
        "    \n",
        "    \n",
        "    \n",
        "    return List"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2HPEDjjJerN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_chunk_size(total_image_number, chunk_size):\n",
        "    list_of_chunks= []\n",
        "    n_of_whole_chunk_sizes = int(total_image_number/chunk_size)\n",
        "    n_of_partial_chunk_sizes = total_image_number%chunk_size\n",
        "    for i in range(n_of_whole_chunk_sizes):\n",
        "        list_of_chunks.append(chunk_size)\n",
        "    if(n_of_partial_chunk_sizes != 0):\n",
        "        list_of_chunks.append(n_of_partial_chunk_sizes)\n",
        "    print(\"List of chunks= \" , list_of_chunks)\n",
        "    print(\"Length of List of chunks= \" , len(list_of_chunks))        \n",
        "    return list_of_chunks       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it_kTWXEbVjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "original_image_width  = 2100\n",
        "original_image_height = 1400\n",
        "image_width = 2080\n",
        "image_height = 1376\n",
        "channel_size = 3\n",
        "number_of_classes = 7 # 7 in this project\n",
        "chunk_size = 1\n",
        "total_test_image_number = len(x_test_List)  # 5546 in ths project\n",
        "start = 0;\n",
        "end = start + chunk_size\n",
        "list_of_chunks = calculate_chunk_size(total_test_image_number, chunk_size)\n",
        "batchSize = 2\n",
        "epoch = 4\n",
        "needResize = False\n",
        "beginA = 0\n",
        "\n",
        "num_testing_image = len(x_test_List)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(dir_csv_output_file, 'a+') as myFile:   # a+ . + == create if not exists\n",
        "              MyCsvWriterObject = csv.writer(myFile)\n",
        "              MyCsvWriterObject.writerow(['Image_Label','EncodedPixels'])\n",
        "\n",
        "# channel last with tensorflow backend\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for beginA in range(len(list_of_chunks)):\n",
        "    \n",
        "    print(\"starting: \" , start, \" \", end)\n",
        "    x_test = np.zeros((list_of_chunks[beginA], image_height, image_width, channel_size),dtype = 'uint8')\n",
        "    \n",
        "    \n",
        "    \n",
        "    #GET X-TRAIN\n",
        "    for j in range(start,end):\n",
        "        print(\"Creating x_test: \" , x_test_List[j].split('/')[6])\n",
        "        image_data = cv2.imread(x_test_List[j])\n",
        "        image_data = image_data.astype('uint8')\n",
        "        image_data = cv2.resize(image_data, (image_width, image_height), interpolation = cv2.INTER_AREA)\n",
        "        x_test[j-start] =  image_data\n",
        "\n",
        "    \n",
        "    \n",
        "    y_pred = model.predict(x_test)  \n",
        "    y_predi = np.argmax(y_pred, axis=3)  \n",
        "\n",
        "###############################3cvs########################################3\n",
        "    with open(dir_csv_output_file, 'a+') as myFile:   # a+ . + == create if not exists\n",
        "              MyCsvWriterObject = csv.writer(myFile)\n",
        "              readCSV = csv.reader(myFile)\n",
        "              for row in readCSV:\n",
        "                if(row[0] == None):\n",
        "                  MyCsvWriterObject.writerow(['Image_Label','EncodedPixels'])\n",
        "                  break\n",
        "                else:\n",
        "                  break\n",
        "            \n",
        "          \n",
        "            \n",
        "              for kkk in range(len(y_predi)):\n",
        "                \n",
        "                    \n",
        "                  filename = x_test_List[kkk].split('/')[6]\n",
        "                  \n",
        "                  print(\"jjj .  \",filename)\n",
        "                  \n",
        "                  \n",
        "                  y_predicted = y_predi[kkk]\n",
        "                  \n",
        "                  for c in range(number_of_classes):\n",
        "                      if c == 0 or c == 6 or c == 5:\n",
        "                          continue\n",
        "                      if(c == 1):\n",
        "                          classid = 'Fish'\n",
        "                      elif(c == 2):\n",
        "                          classid = 'Flower'\n",
        "                      elif(c == 3):\n",
        "                          classid = 'Gravel'    \n",
        "                      elif(c == 4):\n",
        "                          classid = 'Sugar'    \n",
        "                      \n",
        "                      Listofpixels = GetEndodedList(y_predicted,c)\n",
        "                      \n",
        "                                  \n",
        "                                  \n",
        "                      #Listofpixels=[2,3,4,5,6,7,8]\n",
        "\n",
        "                      \n",
        "                      s=''\n",
        "                      for t in range(len(Listofpixels)):\n",
        "                          if t == len(Listofpixels)+1:\n",
        "                              s +=str(Listofpixels[t]) \n",
        "                          else: s +=str(Listofpixels[t])+' '\n",
        "                              \n",
        "\n",
        "                      MyCsvWriterObject.writerow([filename+'_'+str(classid), s])\n",
        "                \n",
        "    \n",
        "    #kkk+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    start = end\n",
        "    if( beginA < len(list_of_chunks)-1):           \n",
        "        end = end + list_of_chunks[beginA+1]\n",
        "    else:\n",
        "        end = end + list_of_chunks[beginA]\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}